{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41b84bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from nilearn import datasets, plotting\n",
    "from nilearn.image import index_img\n",
    "from nilearn.plotting import view_img\n",
    "from nilearn.input_data import NiftiMasker\n",
    "\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import HoverTool, Div\n",
    "from bokeh.layouts import column\n",
    "from bokeh.io import output_file, save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5516ff99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[get_dataset_dir] Dataset found in /root/nilearn_data/development_fmri\n",
      "[get_dataset_dir] Dataset found in /root/nilearn_data/development_fmri/development_fmri\n",
      "[get_dataset_dir] Dataset found in /root/nilearn_data/development_fmri/development_fmri\n"
     ]
    }
   ],
   "source": [
    "data = datasets.fetch_development_fmri(n_subjects=4)\n",
    "subs_fmri_img = [nib.load(data.func[i]) for i in range(len(data.func))]\n",
    "subs_fmri_data = [img.get_fdata() for img in subs_fmri_img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b80c03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/leclei_project/_a_voxel_value_distributions.html'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_flattened_data = [sub.flatten() for sub in subs_fmri_data]\n",
    "combined_voxels = np.concatenate(all_flattened_data)\n",
    "common_bins = np.linspace(combined_voxels.min(), combined_voxels.max(), 101)\n",
    "plots_list = []\n",
    "colors = [\"dodgerblue\", \"orangered\", \"seagreen\", \"purple\"]\n",
    "title = Div(text=\"<h3>Voxel Value Distributions Across Individual Subjects</h3>\",\n",
    "            width=800, align='center')\n",
    "for i, subject_voxels in enumerate(all_flattened_data):\n",
    "    hist, edges = np.histogram(subject_voxels, bins=common_bins)\n",
    "    fig_kwargs = dict(\n",
    "        height=250,\n",
    "        width=800,\n",
    "        title=f\"Distribution for Subject {i+1}\",\n",
    "        tools=\"pan,wheel_zoom,box_zoom,reset,save\",\n",
    "        y_axis_type=\"log\",\n",
    "        outline_line_color=None,\n",
    "        min_border_left=50\n",
    "    )\n",
    "    if i > 0:\n",
    "        fig_kwargs['x_range'] = plots_list[0].x_range\n",
    "    p = figure(**fig_kwargs)\n",
    "    p.yaxis.axis_label = \"Frequency\"\n",
    "    p.xaxis.axis_label = \"Voxel Value\"\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.ygrid.grid_line_color = None\n",
    "    p.quad(\n",
    "        top=hist,\n",
    "        bottom=0.1,\n",
    "        left=edges[:-1],\n",
    "        right=edges[1:],\n",
    "        fill_color=colors[i % len(colors)],\n",
    "        line_color=\"black\",\n",
    "        alpha=0.8\n",
    "    )\n",
    "    hover = HoverTool(tooltips=[(\"Range\", \"@left{0.00} to @right{0.00}\"), (\"Frequency\", \"@top\")])\n",
    "    p.add_tools(hover)\n",
    "    plots_list.append(p)\n",
    "layout = column(*plots_list, spacing=0)\n",
    "final_layout = column(title, layout)\n",
    "output_file(\"_a_voxel_value_distributions.html\", title=\"_a_voxel_value_distributions.html\")\n",
    "save(final_layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8750256",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(7, 7))\n",
    "slice_indices = [15, 20, 25, 30]\n",
    "axes = axes.ravel()\n",
    "for i, slice_index in enumerate(slice_indices):\n",
    "    ax = axes[i]\n",
    "    ax.imshow(subs_fmri_data[0][:, :, slice_index, 0], cmap='gray')\n",
    "    ax.set_title(f\"Slice at index {slice_index}\")\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "fig.suptitle(\"Subject 1 Axial Plane fMRI Slices\")\n",
    "fig.subplots_adjust(top=0.9)\n",
    "plt.savefig(\"_b_sub1_fmri_slices.png\", dpi=300)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6f85795",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/nilearn/plotting/html_stat_map.py:109: UserWarning: Threshold given was 1e-06, but the data has no values below -121.83067321777344. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:868: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "  a.partition(kth, axis=axis, kind=kind, order=order)\n"
     ]
    }
   ],
   "source": [
    "interactive_raw_view = view_img(index_img(subs_fmri_img[0], 100), cmap='Greys', title=\"Subject 1 fMRI View\")\n",
    "interactive_raw_view.save_as_html(\"_c_sub1_interactive_fmri_viewer.html\")\n",
    "with open(\"_c_sub1_interactive_fmri_viewer.html\", \"r\") as file:\n",
    "    content = file.read()\n",
    "content = content.replace(\n",
    "    \"<title>Subject 1 fMRI View</title>\",\n",
    "    \"<title>_c_sub1_interactive_fmri_viewer.html</title>\"\n",
    ")\n",
    "with open(\"_c_sub1_interactive_fmri_viewer.html\", \"w\") as file:\n",
    "    file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaa9cb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z = np.mgrid[-1:1:50j, -1:1:50j, -1:1:50j]\n",
    "brain_data1 = np.swapaxes(subs_fmri_data[0][:,:,:,0], 0, 1)\n",
    "brain_data2 = np.swapaxes(subs_fmri_data[0][:,:,:,100], 0, 1)\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    specs=[[{'type': 'scene'}, {'type': 'scene'}],\n",
    "           [{'type': 'scene', 'colspan': 2}, None]],\n",
    "    subplot_titles=('Time Point 0', 'Time Point 100', 'Overlaid View')\n",
    ")\n",
    "fig.add_trace(go.Isosurface(\n",
    "    x=x.flatten(), y=y.flatten(), z=z.flatten(),\n",
    "    value=brain_data1.flatten(),\n",
    "    isomin=-700, isomax=np.max(brain_data1),\n",
    "    surface_count=1, colorscale='Greys', showscale=False,\n",
    "    caps=dict(x_show=False, y_show=False), name='Time Point 0'\n",
    "), row=1, col=1)\n",
    "fig.add_trace(go.Isosurface(\n",
    "    x=x.flatten(), y=y.flatten(), z=z.flatten(),\n",
    "    value=brain_data2.flatten(),\n",
    "    isomin=-700, isomax=np.max(brain_data2),\n",
    "    surface_count=1, colorscale='Greys', showscale=False,\n",
    "    caps=dict(x_show=False, y_show=False), name='Time Point 100'\n",
    "), row=1, col=2)\n",
    "fig.add_trace(go.Isosurface(\n",
    "    x=x.flatten(), y=y.flatten(), z=z.flatten(),\n",
    "    value=brain_data1.flatten(),\n",
    "    isomin=-700, isomax=np.max(brain_data1),\n",
    "    surface_count=1, colorscale='Blues', name='Time Point 0 (Overlay)',\n",
    "    showscale=False, opacity=0.5, caps=dict(x_show=False, y_show=False)\n",
    "), row=2, col=1)\n",
    "fig.add_trace(go.Isosurface(\n",
    "    x=x.flatten(), y=y.flatten(), z=z.flatten(),\n",
    "    value=brain_data2.flatten(),\n",
    "    isomin=-700, isomax=np.max(brain_data2),\n",
    "    surface_count=1, colorscale='Reds', name='Time Point 100 (Overlay)',\n",
    "    showscale=False, opacity=0.1, caps=dict(x_show=False, y_show=False)\n",
    "), row=2, col=1)\n",
    "axis_settings = dict(visible=False, showticklabels=False, showgrid=False, zeroline=False, title='')\n",
    "fig.update_layout(\n",
    "    title_text='Subject 1 fMRI 3D Isosurface',\n",
    "    title_x=0.5,\n",
    "    height=800, margin=dict(l=0, r=0, b=0, t=60),\n",
    "    scene=dict(xaxis=axis_settings, yaxis=axis_settings, zaxis=axis_settings),\n",
    "    scene2=dict(xaxis=axis_settings, yaxis=axis_settings, zaxis=axis_settings),\n",
    "    scene3=dict(xaxis=axis_settings, yaxis=axis_settings, zaxis=axis_settings)\n",
    ")\n",
    "fig.write_html(\"_d_sub1_fmri_3d_isosurface.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9177e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_data = np.var(subs_fmri_data[0], axis=3)\n",
    "variance_data_swapped = np.swapaxes(variance_data, 0, 1)\n",
    "x, y, z = np.mgrid[-1:1:50j, -1:1:50j, -1:1:50j]\n",
    "fig_variance = go.Figure(data=go.Isosurface(\n",
    "    x=x.flatten(), y=y.flatten(), z=z.flatten(),\n",
    "    value=variance_data_swapped.flatten(),\n",
    "    isomin=np.percentile(variance_data_swapped[variance_data_swapped > 0], 90),\n",
    "    isomax=np.max(variance_data_swapped),\n",
    "    surface_count=200, colorscale='Viridis', colorbar_title_text='Variance',\n",
    "    showscale=False, caps=dict(x_show=False, y_show=False)\n",
    "))\n",
    "fig_variance.update_layout(\n",
    "    title_text='Subject 1 fMRI 3D Variance Over Time',\n",
    "    scene=dict(\n",
    "        xaxis=dict(visible=False), yaxis=dict(visible=False), zaxis=dict(visible=False)\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, b=0, t=40)\n",
    ")\n",
    "fig_variance.write_html(\"_e_sub1_fmri_3d_variance.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96b9ba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "masker = NiftiMasker()\n",
    "masked_data = masker.fit_transform(data.func[0])\n",
    "masked_data_with_confounds = masker.fit_transform(data.func[0], confounds=data.confounds)\n",
    "confound_effect_signal = masked_data - masked_data_with_confounds\n",
    "confounds_img = masker.inverse_transform(confound_effect_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e22e2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "axes = axes.ravel()\n",
    "for i, slice_index in enumerate(slice_indices):\n",
    "    ax = axes[i]\n",
    "    ax.imshow(confounds_img.get_fdata()[:, :, slice_index, 0], cmap='gray')\n",
    "    ax.set_title(f\"Slice at index {slice_index}\")\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "fig.suptitle(\"Subject 1 Axial Plane Confound fMRI Slices\")\n",
    "fig.subplots_adjust(top=0.9)\n",
    "plt.savefig(\"_f_sub1_confound_fmri_slices.png\", dpi=300)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d323bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:868: UserWarning:\n",
      "\n",
      "Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "interactive_confound_view = view_img(index_img(confounds_img, 0), cmap='Greys', title=\"Sub 1 Confound fMRI View\")\n",
    "interactive_confound_view.save_as_html(\"_g_sub1_interactive_confound_fmri_viewer.html\")\n",
    "with open(\"_g_sub1_interactive_confound_fmri_viewer.html\", \"r\") as file:\n",
    "    content = file.read()\n",
    "content = content.replace(\n",
    "    \"<title>Sub 1 Confound fMRI View</title>\",\n",
    "    \"<title>_g_sub1_interactive_confound_fmri_viewer.html</title>\"\n",
    ")\n",
    "with open(\"_g_sub1_interactive_confound_fmri_viewer.html\", \"w\") as file:\n",
    "    file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d59331cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "masker = NiftiMasker()\n",
    "masked_data = masker.fit_transform(data.func[0], confounds=data.confounds)\n",
    "fmri_with_confound = masker.inverse_transform(masked_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "699de757",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:868: UserWarning:\n",
      "\n",
      "Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "interactive_confound_applied_view = view_img(index_img(fmri_with_confound, 0), cmap='Greys', title=\"Sub 1 fMRI w/ Confound View\")\n",
    "interactive_confound_applied_view.save_as_html(\"_h_sub1_interactive_confound_applied_fmri_viewer.html\")\n",
    "with open(\"_h_sub1_interactive_confound_applied_fmri_viewer.html\", \"r\") as file:\n",
    "    content = file.read()\n",
    "content = content.replace(\n",
    "    \"<title>Sub 1 fMRI w/ Confound View</title>\",\n",
    "    \"<title>_h_sub1_interactive_confound_applied_fmri_viewer.html</title>\"\n",
    ")\n",
    "with open(\"_h_sub1_interactive_confound_applied_fmri_viewer.html\", \"w\") as file:\n",
    "    file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b616dc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "masker = NiftiMasker()\n",
    "masked_data = masker.fit_transform(data.func[0], confounds=data.confounds)\n",
    "thresholded_masked_data = masked_data * (masked_data > masked_data.mean())\n",
    "thresholded_img = masker.inverse_transform(thresholded_masked_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf5f0b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:868: UserWarning:\n",
      "\n",
      "Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "interactive_confound_applied_thresh_view = view_img(index_img(thresholded_img, 0), cmap='Greys', title=\"Sub 1 fMRI w/ Confound Thresh View\")\n",
    "interactive_confound_applied_thresh_view.save_as_html(\"_i_sub1_interactive_confound_applied_thresh_fmri_viewer.html\")\n",
    "with open(\"_i_sub1_interactive_confound_applied_thresh_fmri_viewer.html\", \"r\") as file:\n",
    "    content = file.read()\n",
    "content = content.replace(\n",
    "    \"<title>Sub 1 fMRI w/ Confound Thresh View</title>\",\n",
    "    \"<title>_i_sub1_interactive_confound_applied_thresh_fmri_viewer.html</title>\"\n",
    ")\n",
    "with open(\"_i_sub1_interactive_confound_applied_thresh_fmri_viewer.html\", \"w\") as file:\n",
    "    file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41e642db",
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_data = np.var(thresholded_img.get_fdata(), axis=3)\n",
    "variance_data_swapped = np.swapaxes(variance_data, 0, 1)\n",
    "x, y, z = np.mgrid[-1:1:50j, -1:1:50j, -1:1:50j]\n",
    "fig_variance = go.Figure(data=go.Isosurface(\n",
    "    x=x.flatten(), y=y.flatten(), z=z.flatten(),\n",
    "    value=variance_data_swapped.flatten(),\n",
    "    isomin=np.percentile(variance_data_swapped[variance_data_swapped > 0], 90),\n",
    "    isomax=np.max(variance_data_swapped),\n",
    "    surface_count=200, colorscale='Viridis', colorbar_title_text='Variance',\n",
    "    showscale=False, caps=dict(x_show=False, y_show=False)\n",
    "))\n",
    "fig_variance.update_layout(\n",
    "    title_text='Subject 1 fMRI w/ Confound Thresholded 3D Variance Over Time',\n",
    "    scene=dict(\n",
    "        xaxis=dict(visible=False), yaxis=dict(visible=False), zaxis=dict(visible=False)\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, b=0, t=40)\n",
    ")\n",
    "fig_variance.write_html(\"_j_sub1_fmri_confound_thresh_3d_variance.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f50d2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[get_dataset_dir] Dataset found in /root/nilearn_data/schaefer_2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:868: UserWarning:\n",
      "\n",
      "Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "atlas = datasets.fetch_atlas_schaefer_2018()\n",
    "atlas_plot = view_img(atlas.maps, title=\"Schaefer 2018 Atlas\")\n",
    "atlas_plot.save_as_html(\"_m_schaefer_2018_atlas.html\")\n",
    "with open(\"_m_schaefer_2018_atlas.html\", \"r\") as file:\n",
    "    content = file.read()\n",
    "content = content.replace(\n",
    "    \"<title>Schaefer 2018 Atlas</title>\",\n",
    "    \"<title>_m_schaefer_2018_atlas.html</title>\"\n",
    ")\n",
    "with open(\"_m_schaefer_2018_atlas.html\", \"w\") as file:\n",
    "    file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2f5723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import h5py\n",
    "import cv2\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import Video, display\n",
    "from moviepy import VideoFileClip\n",
    "root_data_dir = '../algonauts_2025_challenge_tutorial_data'\n",
    "def load_tsv_file(transcript_path):\n",
    "    transcript_df = pd.read_csv(transcript_path, sep='\\t')\n",
    "    sample_transcript_data = transcript_df.iloc[:20]\n",
    "    print(\"Transcript data (Rows 0 to 20):\")\n",
    "    display(sample_transcript_data)\n",
    "    print(f\"\\nTranscript has {transcript_df.shape[0]} rows (chunks of 1.49 seconds) and {transcript_df.shape[1]} columns.\")\n",
    "def load_transcript(transcript_path):\n",
    "    df = pd.read_csv(transcript_path, sep='\\t')\n",
    "    return df\n",
    "def get_movie_info(movie_path):\n",
    "    cap = cv2.VideoCapture(movie_path)\n",
    "    fps, frame_count = cap.get(cv2.CAP_PROP_FPS), cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    cap.release()\n",
    "    print(f\"Movie FPS: {fps}, Frame Count: {frame_count}\")\n",
    "    return fps, frame_count / fps\n",
    "def split_movie_into_chunks(movie_path, chunk_duration=1.49):\n",
    "    _, video_duration = get_movie_info(movie_path)\n",
    "    chunks = []\n",
    "    start_time = 0.0\n",
    "    while start_time < video_duration:\n",
    "        end_time = min(start_time + chunk_duration, video_duration)\n",
    "        chunks.append((start_time, end_time))\n",
    "        start_time += chunk_duration\n",
    "    return chunks\n",
    "def extract_movie_segment_with_sound(movie_path, start_time, end_time,\n",
    "    output_path='output_segment.mp4'):\n",
    "    movie_segment = VideoFileClip(movie_path).subclipped(start_time, end_time)\n",
    "    print(f\"\\nWriting movie file from {start_time}s until {end_time}s\")\n",
    "    movie_segment.write_videofile(output_path, codec=\"libx264\",\n",
    "        audio_codec=\"aac\", logger=None)\n",
    "    return output_path\n",
    "def display_transcript_and_movie(chunk_index, transcript_df, chunks,\n",
    "    movie_path):\n",
    "    start_time, end_time = chunks[chunk_index]\n",
    "    transcript_chunk = transcript_df.iloc[chunk_index] if chunk_index < len(transcript_df) else None\n",
    "    print(f\"\\nChunk number: {chunk_index + 1}\")\n",
    "    if transcript_chunk is not None and pd.notna(transcript_chunk['text_per_tr']):\n",
    "        print(f\"\\nText: {transcript_chunk['text_per_tr']}\")\n",
    "        print(f\"Words: {transcript_chunk['words_per_tr']}\")\n",
    "        print(f\"Onsets: {transcript_chunk.get('onsets_per_tr', 'N/A')}\")\n",
    "        print(f\"Durations: {transcript_chunk.get('durations_per_tr', 'N/A')}\")\n",
    "    else:\n",
    "        print(\"<No dialogue in this scene>\")\n",
    "    output_movie_path = extract_movie_segment_with_sound(movie_path, start_time,\n",
    "        end_time)\n",
    "    display(Video(output_movie_path, embed=True, width=640, height=480))\n",
    "def create_dropdown_by_text(transcript_df):\n",
    "    options = []\n",
    "    for i, row in transcript_df.iterrows():\n",
    "        if pd.notna(row['text_per_tr']):\n",
    "            options.append((row['text_per_tr'], i))\n",
    "        else:\n",
    "            options.append((\"<No dialogue in this scene>\", i))\n",
    "    return widgets.Dropdown(options=options, description='Select scene:')\n",
    "def plot_fmri_on_brain(chunk_index, fmri_file_path, atlas_path, dataset_name,\n",
    "    hrf_delay):\n",
    "    print(f\"\\nLoading fMRI file: {fmri_file_path}\")\n",
    "    atlas_img = nib.load(atlas_path)\n",
    "    atlas_data = atlas_img.get_fdata()\n",
    "    with h5py.File(fmri_file_path, 'r') as f:\n",
    "        print(f\"Opening fMRI dataset: {dataset_name}\")\n",
    "        fmri_data = f[dataset_name][()]\n",
    "        print(f\"fMRI dataset shape: {fmri_data.shape}\")\n",
    "    if (chunk_index + hrf_delay) > len(fmri_data):\n",
    "        selected_sample = len(fmri_data)\n",
    "    else:\n",
    "        selected_sample = chunk_index + hrf_delay\n",
    "    fmri_sample_data = fmri_data[selected_sample]\n",
    "    print(f\"Extracting fMRI sample {selected_sample+1}.\")\n",
    "    output_data = np.zeros_like(atlas_data)\n",
    "    for parcel_index in range(1000):\n",
    "        output_data[atlas_data == (parcel_index + 1)] = \\\n",
    "            fmri_sample_data[parcel_index]\n",
    "    output_img = nib.Nifti1Image(output_data, affine=atlas_img.affine)\n",
    "    display = plotting.plot_glass_brain(\n",
    "        output_img,\n",
    "        display_mode='lyrz',\n",
    "        cmap='inferno',\n",
    "        colorbar=True,\n",
    "        plot_abs=False)\n",
    "    colorbar = display._cbar\n",
    "    colorbar.set_label(\"fMRI activity\", rotation=90, labelpad=12, fontsize=12)\n",
    "    plotting.show()\n",
    "def get_fmri_on_brain(chunk_index, fmri_file_path, atlas_path, dataset_name,\n",
    "    hrf_delay):\n",
    "    atlas_img = nib.load(atlas_path)\n",
    "    atlas_data = atlas_img.get_fdata()\n",
    "    with h5py.File(fmri_file_path, 'r') as f:\n",
    "        fmri_data = f[dataset_name][()]\n",
    "    if (chunk_index + hrf_delay) > len(fmri_data):\n",
    "        selected_sample = len(fmri_data)\n",
    "    else:\n",
    "        selected_sample = chunk_index + hrf_delay\n",
    "    fmri_sample_data = fmri_data[selected_sample]\n",
    "    output_data = np.zeros_like(atlas_data)\n",
    "    for parcel_index in range(1000):\n",
    "        output_data[atlas_data == (parcel_index + 1)] = \\\n",
    "            fmri_sample_data[parcel_index]\n",
    "    output_img = nib.Nifti1Image(output_data, affine=atlas_img.affine)\n",
    "    return atlas_img, atlas_data, fmri_data, output_data, output_img\n",
    "def interface_display_transcript_movie_brain(movie_path, transcript_path,\n",
    "    fmri_file_path, atlas_path, dataset_name, hrf_delay):\n",
    "    transcript_df = load_transcript(transcript_path)\n",
    "    chunks = split_movie_into_chunks(movie_path)\n",
    "    dropdown = create_dropdown_by_text(transcript_df)\n",
    "    output = widgets.Output()\n",
    "    def on_chunk_select(change):\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            chunk_index = dropdown.value\n",
    "            display_transcript_and_movie(chunk_index, transcript_df, chunks,\n",
    "                movie_path)\n",
    "            plot_fmri_on_brain(chunk_index, fmri_file_path, atlas_path,\n",
    "                dataset_name, hrf_delay)\n",
    "    dropdown.observe(on_chunk_select, names='value')\n",
    "    display(dropdown, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bef56125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie FPS: 29.968454258675077, Frame Count: 26412.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c79ca087a40f4ae1ba8fe441fd29661d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Select scene:', options=(('<No dialogue in this scene>', 0), ('<No dialogue in this scenâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c3a7a3a30ae406e986146621d04824f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# HRF delay parameter\n",
    "hrf_delay = 0  #@param {type:\"slider\", min:0, max:10, step:1}\n",
    "\n",
    "# Define file paths and dataset name\n",
    "movie_path = root_data_dir + \"/algonauts_2025.competitors/stimuli/movies/friends/s1/friends_s01e01a.mkv\"\n",
    "transcript_path = root_data_dir + \"/algonauts_2025.competitors/stimuli/transcripts/friends/s1/friends_s01e01a.tsv\"\n",
    "fmri_file_path = root_data_dir + \"/algonauts_2025.competitors/fmri/sub-01/func/sub-01_task-friends_space-MNI152NLin2009cAsym_atlas-Schaefer18_parcel-1000Par7Net_desc-s123456_bold.h5\"\n",
    "atlas_path = root_data_dir + \"/algonauts_2025.competitors/fmri/sub-01/atlas/sub-01_space-MNI152NLin2009cAsym_atlas-Schaefer18_parcel-1000Par7Net_desc-dseg_parcellation.nii.gz\"\n",
    "dataset_name = \"ses-003_task-s01e01a\"\n",
    "\n",
    "# Get the selected transcript row/chunk from the interface\n",
    "interface_display_transcript_movie_brain(movie_path, transcript_path,\n",
    "    fmri_file_path, atlas_path, dataset_name, hrf_delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1461a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_img, atlas_data, fmri_data, output_data, output_img = get_fmri_on_brain(129, fmri_file_path, atlas_path, dataset_name, hrf_delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ea662d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:868: UserWarning:\n",
      "\n",
      "Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "algonauts_fmri_viewer = view_img(output_img, title=\"Algonauts Sorry fMRI View\")\n",
    "algonauts_fmri_viewer.save_as_html(\"_p_algonauts_fmri_viewer.html\")\n",
    "with open(\"_p_algonauts_fmri_viewer.html\", \"r\") as file:\n",
    "    content = file.read()\n",
    "content = content.replace(\n",
    "    \"<title>Algonauts Sorry fMRI View</title>\",\n",
    "    \"<title>_p_algonauts_fmri_viewer.html</title>\"\n",
    ")\n",
    "with open(\"_p_algonauts_fmri_viewer.html\", \"w\") as file:\n",
    "    file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bde814db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/leclei_project/_q_algonauts_voxel_value_distribution.html'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_voxels = fmri_data.flatten()\n",
    "hist, edges = np.histogram(all_voxels, bins=100)\n",
    "p = figure(\n",
    "    height=400,\n",
    "    width=800,\n",
    "    title=\"Overall Voxel Intensity Distribution (All Time Points)\",\n",
    "    tools=\"pan,wheel_zoom,box_zoom,reset,save\",\n",
    "    y_axis_type=\"log\",\n",
    "    outline_line_color=None,\n",
    "    min_border_left=50\n",
    ")\n",
    "p.yaxis.axis_label = \"Frequency (log scale)\"\n",
    "p.xaxis.axis_label = \"Voxel Signal Intensity\"\n",
    "p.xgrid.grid_line_color = None\n",
    "p.ygrid.grid_line_alpha = 0.5\n",
    "p.ygrid.grid_line_dash = 'dashed'\n",
    "p.quad(\n",
    "    top=hist,\n",
    "    bottom=0.1,\n",
    "    left=edges[:-1],\n",
    "    right=edges[1:],\n",
    "    fill_color=\"dodgerblue\",\n",
    "    line_color=\"black\",\n",
    "    alpha=0.8\n",
    ")\n",
    "hover = HoverTool(tooltips=[(\"Range\", \"@left{0.00} to @right{0.00}\"), (\"Frequency\", \"@top\")])\n",
    "p.add_tools(hover)\n",
    "output_file(\"_q_algonauts_voxel_value_distribution.html\", title=\"_q_algonauts_voxel_value_distribution.html\")\n",
    "save(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc42f285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.connectome import ConnectivityMeasure\n",
    "correlation_measure = ConnectivityMeasure(kind='correlation')\n",
    "correlation_matrix = correlation_measure.fit_transform([fmri_data])[0]\n",
    "np.fill_diagonal(correlation_matrix, 0)\n",
    "fig = plotting.plot_matrix(correlation_matrix, figure=(10, 8), labels=np.arange(1, 1001).tolist(),\n",
    "                     vmax=0.8, vmin=-0.8, reorder=True)\n",
    "fig.figure.savefig(\"_r_algonauts_correlation_matrix.png\", dpi=300)\n",
    "plt.close(fig.figure)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
